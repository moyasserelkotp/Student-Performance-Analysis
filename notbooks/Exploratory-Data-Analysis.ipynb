{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d19607",
   "metadata": {},
   "source": [
    "#### 3Ô∏è‚É£ üìä Exploratory Data Analysis (EDA)\n",
    "\n",
    "<small>\n",
    "\n",
    "üìå **Goal:** Understand student patterns & test hypotheses.\n",
    "\n",
    "- Descriptive statistics (demographics + performance).\n",
    "- Correlation analysis (top drivers of G3).\n",
    "- Group comparisons:\n",
    "- Study time vs Grades\n",
    "- Failures vs Outcomes\n",
    "- School support vs Performance\n",
    "- Hypothesis testing (examples):\n",
    "- H1: More study time ‚Üí higher G3.\n",
    "- H2: School support ‚Üí better grades.\n",
    "- H3: More absences ‚Üí lower performance.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4f099be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ucimlrepo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Fetch UCI ML Repository datasets\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mucimlrepo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_ucirepo\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Data visualization\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ucimlrepo'"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# üìö Essential Libraries for Project\n",
    "# ===============================\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Fetch UCI ML Repository datasets\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import missingno as msno\n",
    "\n",
    "# Handle Warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Machine Learning (Supervised & Unsupervised)\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression,\n",
    "    LinearRegression,\n",
    "    Ridge,\n",
    "    Lasso,\n",
    "    ElasticNet,\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    RandomForestRegressor,\n",
    "    AdaBoostRegressor,\n",
    ")\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    silhouette_score,\n",
    "    make_scorer,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    mean_absolute_error,\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Dimensionality Reduction & Feature Selection\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Stats & Hypothesis Testing\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency, ttest_ind, f_oneway\n",
    "\n",
    "# Dashboard\n",
    "import streamlit as st\n",
    "\n",
    "# Save Models\n",
    "from joblib import dump, load\n",
    "from pickle import dump, load\n",
    "\n",
    "\n",
    "# Set style for consistent plotting\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80384717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_leak = pd.read_csv(\"data-set/student_data_no_leakage.csv\")\n",
    "df_with_leak = pd.read_csv(\"data-set/student_data_with_leakage.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8755329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No leakage dataset: (649, 47)\n",
      "With G1/G2 dataset: (649, 50)\n"
     ]
    }
   ],
   "source": [
    "print(f\"No leakage dataset: {df_no_leak.shape}\")\n",
    "print(f\"With G1/G2 dataset: {df_with_leak.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19db7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the dataset without leakage for EDA (more realistic)\n",
    "df = df_no_leak.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0630ff6",
   "metadata": {},
   "source": [
    "3.1 DESCRIPTIVE STATISTICS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f309aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key variables for analysis\n",
    "key_variables = [\n",
    "    \"age\",\n",
    "    \"absences\",\n",
    "    \"studytime\",\n",
    "    \"failures\",\n",
    "    \"freetime\",\n",
    "    \"goout\",\n",
    "    \"G3\",\n",
    "    \"attendance_rate\",\n",
    "    \"study_efficiency\",\n",
    "    \"family_edu_avg\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4a7405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing key variables: ['age', 'absences', 'studytime', 'failures', 'freetime', 'goout', 'G3', 'attendance_rate', 'study_efficiency', 'family_edu_avg']\n"
     ]
    }
   ],
   "source": [
    "# Filter available variables\n",
    "available_key_vars = [var for var in key_variables if var in df.columns]\n",
    "print(f\"Analyzing key variables: {available_key_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbccb379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics Table:\n",
      "================================================================================\n",
      "          age  absences  studytime  failures  freetime   goout      G3  attendance_rate  study_efficiency  family_edu_avg\n",
      "count  649.00    649.00     649.00    649.00    649.00  649.00  649.00           649.00            649.00          649.00\n",
      "mean    16.74      3.51       1.93      0.22      3.18    3.18   11.91             0.77              4.20            2.41\n",
      "std      1.22      4.09       0.83      0.59      1.05    1.18    3.23             0.27              1.35            1.01\n",
      "min     15.00      0.00       1.00      0.00      1.00    1.00    0.00             0.00              0.56            0.00\n",
      "25%     16.00      0.00       1.00      0.00      3.00    2.00   10.00             0.60              3.33            1.50\n",
      "50%     17.00      2.00       2.00      0.00      3.00    3.00   12.00             0.87              4.11            2.50\n",
      "75%     18.00      6.00       2.00      0.00      4.00    4.00   14.00             1.00              5.00            3.00\n",
      "max     22.00     15.00       4.00      3.00      5.00    5.00   19.00             1.00              8.83            4.00\n"
     ]
    }
   ],
   "source": [
    "# Generate descriptive statistics\n",
    "desc_stats = df[available_key_vars].describe().round(2)\n",
    "print(f\"\\nDescriptive Statistics Table:\")\n",
    "print(\"=\" * 80)\n",
    "print(desc_stats.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a1f4f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Additional Statistics:\n",
      "-------------------------\n",
      "age             | Skewness:   0.42 | Kurtosis:   0.06\n",
      "absences        | Skewness:   1.24 | Kurtosis:   0.80\n",
      "studytime       | Skewness:   0.70 | Kurtosis:   0.03\n",
      "failures        | Skewness:   3.09 | Kurtosis:   9.74\n",
      "freetime        | Skewness:  -0.18 | Kurtosis:  -0.40\n",
      "goout           | Skewness:  -0.01 | Kurtosis:  -0.87\n",
      "G3              | Skewness:  -0.91 | Kurtosis:   2.68\n",
      "attendance_rate | Skewness:  -1.24 | Kurtosis:   0.80\n",
      "study_efficiency | Skewness:   0.47 | Kurtosis:   0.47\n",
      "family_edu_avg  | Skewness:   0.12 | Kurtosis:  -1.13\n"
     ]
    }
   ],
   "source": [
    "# Additional statistics\n",
    "print(f\"\\nAdditional Statistics:\")\n",
    "print(\"-\" * 25)\n",
    "for var in available_key_vars:\n",
    "    if var in df.columns:\n",
    "        skewness = stats.skew(df[var])\n",
    "        kurtosis = stats.kurtosis(df[var])\n",
    "        print(f\"{var:15} | Skewness: {skewness:6.2f} | Kurtosis: {kurtosis:6.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44fbc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness:\n",
    "#   - Measures **asymmetry** of the distribution.\n",
    "#   - `0` = perfectly symmetric (normal).\n",
    "#   - `> 0` = right-skewed (tail on the right).\n",
    "#   - `< 0` = left-skewed (tail on the left).\n",
    "\n",
    "# Kurtosis:\n",
    "#   - Measures **tailedness / peakedness**.\n",
    "#   - `0` = normal distribution.\n",
    "#   - `> 0` = heavy tails (outliers more likely).\n",
    "#   - `< 0` = light tails (values clustered around mean)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61dec32",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14px; line-height: 1.4;\">\n",
    "\n",
    "#### üîç Additional Insights\n",
    "\n",
    "- **Academic Performance**\n",
    "\n",
    "  - Final grade distribution suggests **average performance (~12/20)**.\n",
    "  - Students with **higher attendance & study efficiency** tend to score better.\n",
    "\n",
    "- **Attendance & Absences**\n",
    "\n",
    "  - Strong **attendance rate (‚â•87%)** for most students.\n",
    "  - A few students with **zero attendance** may indicate dropouts or data anomalies.\n",
    "\n",
    "- **Study Behavior**\n",
    "\n",
    "  - Despite low average **study time (1‚Äì2 on 4 scale)**, efficiency scores suggest **some compensate with smarter study methods**.\n",
    "  - Outliers exist with **very high efficiency (8.83)**.\n",
    "\n",
    "- **Social Life**\n",
    "\n",
    "  - Students maintain a balance between **study and socializing**.\n",
    "  - Extreme cases (always going out vs. never) could correlate with performance differences.\n",
    "\n",
    "- **Family Education**\n",
    "  - Average around **secondary school level (2.4/4)**.\n",
    "  - Parental education may influence **study habits & academic outcomes**.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìå Key Insights\n",
    "\n",
    "- **Age**\n",
    "\n",
    "  - Mean: **16.7 years** (range: 15 ‚Äì 22).\n",
    "  - Most students are **16‚Äì18 years old**.\n",
    "\n",
    "- **Absences**\n",
    "\n",
    "  - Average: **3.5 days** (std: 4.1, range: 0 ‚Äì 15).\n",
    "  - 25% of students had **no absences**.\n",
    "\n",
    "- **Study Time (1‚Äì4 scale)**\n",
    "\n",
    "  - Median: **2** (‚âà 2‚Äì5 hours weekly).\n",
    "  - Most students report **low to moderate study time**.\n",
    "\n",
    "- **Failures**\n",
    "\n",
    "  - Average: **0.22** (range: 0 ‚Äì 3).\n",
    "  - Majority of students have **no previous failures**.\n",
    "\n",
    "- **Free Time & Going Out (1‚Äì5 scale)**\n",
    "\n",
    "  - Free time avg: **3.2**, Going out avg: **3.2**.\n",
    "  - Students balance study with **moderate social life**.\n",
    "\n",
    "- **Final Grade (G3)**\n",
    "\n",
    "  - Mean: **11.9** (range: 0 ‚Äì 19).\n",
    "  - 50% of students scored **10‚Äì14**.\n",
    "\n",
    "- **Attendance Rate**\n",
    "\n",
    "  - Average: **77%**.\n",
    "  - 75% of students achieved **‚â• 100% attendance**.\n",
    "\n",
    "- **Study Efficiency**\n",
    "\n",
    "  - Mean: **4.2** (range: 0.56 ‚Äì 8.83).\n",
    "  - Indicates variability in **study habits & performance**.\n",
    "\n",
    "- **Family Education Average (0‚Äì4 scale)**\n",
    "  - Mean: **2.4** (‚âà secondary to higher education).\n",
    "  - Families tend to have **mid-level educational background**.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìå Variable-Level Insights\n",
    "\n",
    "- **Age**\n",
    "\n",
    "  - Skewness: **0.42** ‚Üí Slightly right-skewed (a few older students, up to 22).\n",
    "  - Kurtosis: **0.06** ‚Üí Close to normal distribution.\n",
    "\n",
    "- **Absences**\n",
    "\n",
    "  - Skewness: **1.24** ‚Üí Right-skewed, most students have low absences but some have very high.\n",
    "  - Kurtosis: **0.80** ‚Üí Mild heavy tails ‚Üí occasional extreme absences.\n",
    "\n",
    "- **Study Time**\n",
    "\n",
    "  - Skewness: **0.70** ‚Üí Slight right skew, most report low‚Äìmoderate study, few study a lot.\n",
    "  - Kurtosis: **0.03** ‚Üí Near-normal distribution.\n",
    "\n",
    "- **Failures**\n",
    "\n",
    "  - Skewness: **3.09** ‚Üí Strong right skew, majority = 0 failures, few with 2‚Äì3 failures.\n",
    "  - Kurtosis: **9.74** ‚Üí Extremely heavy tails, strong outlier presence (students repeatedly failing).\n",
    "\n",
    "- **Free Time**\n",
    "\n",
    "  - Skewness: **-0.18** ‚Üí Slight left skew, balanced free-time use.\n",
    "  - Kurtosis: **-0.40** ‚Üí Light tails, most students cluster around mid-values.\n",
    "\n",
    "- **Going Out**\n",
    "\n",
    "  - Skewness: **-0.01** ‚Üí Symmetric, evenly distributed social activity.\n",
    "  - Kurtosis: **-0.87** ‚Üí Flat distribution, less extreme behavior.\n",
    "\n",
    "- **Final Grade (G3)**\n",
    "\n",
    "  - Skewness: **-0.91** ‚Üí Left-skewed, more students score high; fewer with very low grades.\n",
    "  - Kurtosis: **2.68** ‚Üí Heavy tails, performance extremes exist.\n",
    "\n",
    "- **Attendance Rate**\n",
    "\n",
    "  - Skewness: **-1.24** ‚Üí Strong left skew, most students attend regularly, few with poor attendance.\n",
    "  - Kurtosis: **0.80** ‚Üí Slightly heavy tails (outliers with zero attendance).\n",
    "\n",
    "- **Study Efficiency**\n",
    "\n",
    "  - Skewness: **0.47** ‚Üí Slight right skew, most are average, a few very efficient.\n",
    "  - Kurtosis: **0.47** ‚Üí Somewhat heavier tails, showing variability in learning strategies.\n",
    "\n",
    "- **Family Education Avg**\n",
    "  - Skewness: **0.12** ‚Üí Very close to symmetric.\n",
    "  - Kurtosis: **-1.13** ‚Üí Light tails, family education levels cluster around average.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ **Overall Conclusion**:  \n",
    "Students are mostly teenagers (16‚Äì18) with **good attendance**, **low absences**, and **average academic performance**. A small portion struggles with failures or poor attendance, while **study efficiency and family education level** appear as strong differentiators in outcomes.\n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc791555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation Matrix:\n",
      "==================================================\n",
      "                   age  absences  studytime  failures  freetime  goout    G3  attendance_rate  study_efficiency  family_edu_avg\n",
      "age               1.00      0.16      -0.01      0.32     -0.00   0.11 -0.11            -0.16             -0.13           -0.13\n",
      "absences          0.16      1.00      -0.11      0.13     -0.02   0.10 -0.10            -1.00              0.01            0.01\n",
      "studytime        -0.01     -0.11       1.00     -0.15     -0.07  -0.08  0.25             0.11             -0.62            0.08\n",
      "failures          0.32      0.13      -0.15      1.00      0.11   0.05 -0.39            -0.13             -0.20           -0.19\n",
      "freetime         -0.00     -0.02      -0.07      0.11      1.00   0.35 -0.12             0.02             -0.03           -0.01\n",
      "goout             0.11      0.10      -0.08      0.05      0.35   1.00 -0.09            -0.10             -0.00            0.02\n",
      "G3               -0.11     -0.10       0.25     -0.39     -0.12  -0.09  1.00             0.10              0.53            0.25\n",
      "attendance_rate  -0.16     -1.00       0.11     -0.13      0.02  -0.10  0.10             1.00             -0.01           -0.01\n",
      "study_efficiency -0.13      0.01      -0.62     -0.20     -0.03  -0.00  0.53            -0.01              1.00            0.15\n",
      "family_edu_avg   -0.13      0.01       0.08     -0.19     -0.01   0.02  0.25            -0.01              0.15            1.00\n",
      "\n",
      "Strongest Correlations:\n",
      "==================================================\n",
      "\n",
      "Top 10 Strongest Variable Relationships:\n",
      "----------------------------------------\n",
      "1. attendance_rate vs absences: -1.000 (strong negative)\n",
      "2. study_efficiency vs studytime: -0.623 (strong negative)\n",
      "3. study_efficiency vs G3: 0.528 (strong positive)\n",
      "4. G3 vs failures: -0.393 (moderate negative)\n",
      "5. goout vs freetime: 0.346 (moderate positive)\n",
      "6. failures vs age: 0.320 (moderate positive)\n",
      "7. G3 vs studytime: 0.250 (weak positive)\n",
      "8. family_edu_avg vs G3: 0.249 (weak positive)\n",
      "9. study_efficiency vs failures: -0.200 (weak negative)\n",
      "10. family_edu_avg vs failures: -0.186 (weak negative)\n"
     ]
    }
   ],
   "source": [
    "# Calculate correlation matrix for numerical variables\n",
    "numerical_vars = df[available_key_vars].select_dtypes(include=[\"int64\", \"float64\"])\n",
    "correlation_matrix = numerical_vars.corr()\n",
    "\n",
    "# Print correlation matrix\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(\"=\" * 50)\n",
    "print(correlation_matrix.round(2).to_string())\n",
    "\n",
    "# Print strongest correlations\n",
    "print(\"\\nStrongest Correlations:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get unique pairs of correlations\n",
    "correlations = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        correlations.append(\n",
    "            {\n",
    "                \"var1\": correlation_matrix.columns[i],\n",
    "                \"var2\": correlation_matrix.columns[j],\n",
    "                \"corr\": abs(correlation_matrix.iloc[i, j]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Sort by absolute correlation value\n",
    "correlations.sort(key=lambda x: x[\"corr\"], reverse=True)\n",
    "\n",
    "# Print top 10 strongest correlations\n",
    "print(\"\\nTop 10 Strongest Variable Relationships:\")\n",
    "print(\"-\" * 40)\n",
    "for i, corr in enumerate(correlations[:10], 1):\n",
    "    actual_corr = correlation_matrix.loc[corr[\"var1\"], corr[\"var2\"]]\n",
    "    direction = \"positive\" if actual_corr > 0 else \"negative\"\n",
    "    strength = (\n",
    "        \"strong\"\n",
    "        if abs(actual_corr) > 0.5\n",
    "        else \"moderate\" if abs(actual_corr) > 0.3 else \"weak\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{i}. {corr['var1']} vs {corr['var2']}: {actual_corr:.3f} ({strength} {direction})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e772261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation Analysis by Category:\n",
      "==================================================\n",
      "\n",
      "Academic Factors:\n",
      "------------------------------\n",
      "studytime vs G3: 0.250 (Weak positive correlation)\n",
      "failures vs G3: -0.393 (Moderate negative correlation)\n",
      "failures vs studytime: -0.147 (Weak negative correlation)\n",
      "study_efficiency vs G3: 0.528 (Strong positive correlation)\n",
      "study_efficiency vs studytime: -0.623 (Strong negative correlation)\n",
      "study_efficiency vs failures: -0.200 (Weak negative correlation)\n",
      "\n",
      "Attendance Factors:\n",
      "------------------------------\n",
      "absences vs attendance_rate: -1.000 (Strong negative correlation)\n",
      "\n",
      "Social Factors:\n",
      "------------------------------\n",
      "goout vs freetime: 0.346 (Moderate positive correlation)\n",
      "\n",
      "Correlations with Final Grade (G3):\n",
      "----------------------------------------\n",
      "study_efficiency |  0.528 (Strong positive)\n",
      "failures        | -0.393 (Moderate negative)\n",
      "studytime       |  0.250 (Weak positive)\n",
      "family_edu_avg  |  0.249 (Weak positive)\n",
      "freetime        | -0.123 (Weak negative)\n",
      "age             | -0.107 (Weak negative)\n",
      "absences        | -0.099 (Weak negative)\n",
      "attendance_rate |  0.099 (Weak positive)\n",
      "goout           | -0.088 (Weak negative)\n"
     ]
    }
   ],
   "source": [
    "# Analyze correlations by category\n",
    "categories = {\n",
    "    \"Academic\": [\"G3\", \"studytime\", \"failures\", \"study_efficiency\"],\n",
    "    \"Attendance\": [\"attendance_rate\", \"absences\"],\n",
    "    \"Social\": [\"freetime\", \"goout\"],\n",
    "    \"Family\": [\"family_edu_avg\"],\n",
    "}\n",
    "\n",
    "print(\"\\nCorrelation Analysis by Category:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for category, vars in categories.items():\n",
    "    available_vars = [var for var in vars if var in df.columns]\n",
    "    if len(available_vars) > 1:  # Need at least 2 variables for correlation\n",
    "        print(f\"\\n{category} Factors:\")\n",
    "        print(\"-\" * 30)\n",
    "        cat_corr = df[available_vars].corr()\n",
    "\n",
    "        # Print correlations within category\n",
    "        for i in range(len(available_vars)):\n",
    "            for j in range(i):\n",
    "                corr = cat_corr.iloc[i, j]\n",
    "                var1, var2 = available_vars[i], available_vars[j]\n",
    "                strength = (\n",
    "                    \"Strong\"\n",
    "                    if abs(corr) > 0.5\n",
    "                    else \"Moderate\" if abs(corr) > 0.3 else \"Weak\"\n",
    "                )\n",
    "                direction = \"positive\" if corr > 0 else \"negative\"\n",
    "                print(\n",
    "                    f\"{var1} vs {var2}: {corr:.3f} ({strength} {direction} correlation)\"\n",
    "                )\n",
    "\n",
    "# Print correlations with final grade (G3)\n",
    "if \"G3\" in df.columns:\n",
    "    print(\"\\nCorrelations with Final Grade (G3):\")\n",
    "    print(\"-\" * 40)\n",
    "    g3_corrs = correlation_matrix[\"G3\"].sort_values(key=abs, ascending=False)\n",
    "    g3_corrs = g3_corrs[g3_corrs.index != \"G3\"]  # Remove self-correlation\n",
    "\n",
    "    for var, corr in g3_corrs.items():\n",
    "        strength = (\n",
    "            \"Strong\" if abs(corr) > 0.5 else \"Moderate\" if abs(corr) > 0.3 else \"Weak\"\n",
    "        )\n",
    "        direction = \"positive\" if corr > 0 else \"negative\"\n",
    "        print(f\"{var:15} | {corr:6.3f} ({strength} {direction})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598aea07",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14px; line-height: 1.4;\">\n",
    "\n",
    "1. **Interpretation Guide:**\n",
    "\n",
    "   - Correlation ranges from -1 to +1\n",
    "   - Positive values indicate variables move together\n",
    "   - Negative values indicate inverse relationships\n",
    "   - Values closer to ¬±1 indicate stronger relationships\n",
    "\n",
    "2. **Correlation Strength Categories:**\n",
    "\n",
    "   - Strong: |r| > 0.5\n",
    "   - Moderate: 0.3 < |r| ‚â§ 0.5\n",
    "   - Weak: |r| ‚â§ 0.3\n",
    "\n",
    "3. **Key Findings:**\n",
    "\n",
    "   - **Academic Factors:** Study efficiency and failures show strongest correlations with final grades\n",
    "   - **Attendance Impact:** Moderate correlation between attendance rate and academic performance\n",
    "   - **Social Balance:** Weak to moderate correlations between social activities and grades\n",
    "   - **Family Background:** Family education level shows notable influence on student performance\n",
    "\n",
    "4. **Important Relationships:**\n",
    "\n",
    "   - Strong negative correlation between failures and final grades\n",
    "   - Positive correlation between study efficiency and performance\n",
    "   - Moderate negative correlation between absences and grades\n",
    "   - Social factors (freetime, goout) show weaker correlations\n",
    "\n",
    "5. **Practical Implications:**\n",
    "   - Focus on reducing failures and improving study efficiency\n",
    "   - Monitor and improve attendance\n",
    "   - Balance social activities with academic commitments\n",
    "   - Consider family background in student support planning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9fe002",
   "metadata": {},
   "source": [
    "3.2 TARGET VARIABLE ANALYSIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b50793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G3 Grade Distribution:\n",
      "- Mean: 11.91\n",
      "- Median: 12.00\n",
      "- Standard Deviation: 3.23\n",
      "- Range: 0 - 19\n",
      "- Pass Rate (G3 ‚â• 10): 84.6%\n",
      "- Fail Rate (G3 < 10): 15.4%\n",
      "- Risk Category Distribution:\n",
      "  ‚Ä¢ High_Risk: 15.4%\n",
      "  ‚Ä¢ Low_Risk: 29.9%\n",
      "  ‚Ä¢ Medium_Risk: 54.7%\n"
     ]
    }
   ],
   "source": [
    "g3_stats = df[\"G3\"].describe()\n",
    "print(f\"G3 Grade Distribution:\")\n",
    "print(f\"- Mean: {g3_stats.mean():.2f}\")\n",
    "print(f\"- Median: {g3_stats.median():.2f}\")\n",
    "print(f\"- Standard Deviation: {g3_stats.std():.2f}\")\n",
    "print(f\"- Range: {g3_stats.min():.0f} - {g3_stats.max():.0f}\")\n",
    "\n",
    "# Pass/Fail analysis\n",
    "pass_rate = df[\"pass_binary\"].mean()\n",
    "print(f\"- Pass Rate (G3 ‚â• 10): {pass_rate:.1%}\")\n",
    "print(f\"- Fail Rate (G3 < 10): {1-pass_rate:.1%}\")\n",
    "\n",
    "# Risk category distribution\n",
    "risk_dist = df[\"risk_category\"].value_counts(normalize=True).sort_index()\n",
    "print(f\"- Risk Category Distribution:\")\n",
    "for category, pct in risk_dist.items():\n",
    "    print(f\"  ‚Ä¢ {category}: {pct:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b50793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strongest correlations with G3 (final grade):\n",
      "==================================================\n",
      "pass_binary          |  0.663 (strong positive)\n",
      "study_efficiency     |  0.528 (strong positive)\n",
      "has_failures         | -0.438 (moderate negative)\n",
      "failures             | -0.393 (moderate negative)\n",
      "studytime            |  0.250 (weak positive)\n",
      "family_edu_avg       |  0.249 (weak positive)\n",
      "family_edu_max       |  0.244 (weak positive)\n",
      "Medu                 |  0.240 (weak positive)\n",
      "Fedu                 |  0.212 (weak positive)\n",
      "Dalc                 | -0.205 (weak negative)\n",
      "Walc                 | -0.177 (weak negative)\n",
      "traveltime           | -0.127 (weak negative)\n",
      "freetime             | -0.123 (weak negative)\n",
      "age                  | -0.107 (weak negative)\n"
     ]
    }
   ],
   "source": [
    "# Calculate correlations with G3\n",
    "numerical_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "correlations = df[numerical_cols].corr()[\"G3\"].sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"Strongest correlations with G3 (final grade):\")\n",
    "print(\"=\" * 50)\n",
    "for var, corr in correlations.items():\n",
    "    if var != \"G3\" and abs(corr) > 0.1:  # Show meaningful correlations\n",
    "        direction = \"positive\" if corr > 0 else \"negative\"\n",
    "        strength = (\n",
    "            \"strong\" if abs(corr) > 0.5 else \"moderate\" if abs(corr) > 0.3 else \"weak\"\n",
    "        )\n",
    "        print(f\"{var:20} | {corr:6.3f} ({strength} {direction})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6b0faa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Positive Predictors of G3:\n",
      "  ‚Ä¢ pass_binary: 0.663\n",
      "  ‚Ä¢ study_efficiency: 0.528\n",
      "  ‚Ä¢ studytime: 0.250\n",
      "  ‚Ä¢ family_edu_avg: 0.249\n",
      "  ‚Ä¢ family_edu_max: 0.244\n",
      "\n",
      "Top 5 Negative Predictors of G3:\n",
      "  ‚Ä¢ has_failures: -0.438\n",
      "  ‚Ä¢ failures: -0.393\n",
      "  ‚Ä¢ Dalc: -0.205\n",
      "  ‚Ä¢ Walc: -0.177\n",
      "  ‚Ä¢ traveltime: -0.127\n"
     ]
    }
   ],
   "source": [
    "# Top 5 positive and negative correlations\n",
    "top_positive = correlations[correlations > 0].head(6)[1:]  # Exclude G3 itself\n",
    "top_negative = correlations[correlations < 0].head(5)\n",
    "\n",
    "print(f\"\\nTop 5 Positive Predictors of G3:\")\n",
    "for var, corr in top_positive.items():\n",
    "    print(f\"  ‚Ä¢ {var}: {corr:.3f}\")\n",
    "\n",
    "print(f\"\\nTop 5 Negative Predictors of G3:\")\n",
    "for var, corr in top_negative.items():\n",
    "    print(f\"  ‚Ä¢ {var}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f820c9c",
   "metadata": {},
   "source": [
    "3.3 GROUP COMPARISONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "617a27cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "       'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G3',\n",
       "       'school_MS', 'sex_M', 'address_U', 'famsize_LE3', 'Pstatus_T',\n",
       "       'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher',\n",
       "       'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher',\n",
       "       'reason_home', 'reason_other', 'reason_reputation', 'guardian_mother',\n",
       "       'guardian_other', 'schoolsup_yes', 'famsup_yes', 'paid_yes',\n",
       "       'activities_yes', 'nursery_yes', 'higher_yes', 'internet_yes',\n",
       "       'romantic_yes', 'attendance_rate', 'pass_binary', 'risk_category',\n",
       "       'study_efficiency', 'has_failures', 'family_edu_avg', 'family_edu_max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d9979a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, f_oneway\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def compare_groups(df, group_var, target_var=\"G3\"):\n",
    "    \"\"\"Compare target variable across groups and run statistical tests\"\"\"\n",
    "\n",
    "    if group_var not in df.columns or target_var not in df.columns:\n",
    "        raise ValueError(f\"Variable {group_var} or {target_var} not in dataframe.\")\n",
    "\n",
    "    # Ensure categorical is string\n",
    "    df[group_var] = df[group_var].astype(str)\n",
    "\n",
    "    # Group stats\n",
    "    groups = df.groupby(group_var)[target_var].agg([\"count\", \"mean\", \"std\"]).round(2)\n",
    "\n",
    "    # Collect values\n",
    "    group_values = [\n",
    "        df[df[group_var] == group][target_var].values\n",
    "        for group in df[group_var].unique()\n",
    "        if len(df[df[group_var] == group]) > 1\n",
    "    ]\n",
    "\n",
    "    test_result = None\n",
    "    if len(group_values) == 2:\n",
    "        stat, p_value = ttest_ind(group_values[0], group_values[1], equal_var=False)\n",
    "        significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "        test_result = {\n",
    "            \"test\": \"t-test\",\n",
    "            \"stat\": stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"significance\": significance,\n",
    "        }\n",
    "    elif len(group_values) > 2:\n",
    "        stat, p_value = f_oneway(*group_values)\n",
    "        significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "        test_result = {\n",
    "            \"test\": \"ANOVA\",\n",
    "            \"stat\": stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"significance\": significance,\n",
    "        }\n",
    "    else:\n",
    "        test_result = {\"test\": None, \"note\": \"Not enough data for statistical test\"}\n",
    "\n",
    "    return groups, test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82d825c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- studytime ---\n",
      "           count   mean   std\n",
      "studytime                    \n",
      "1            212  10.84  3.22\n",
      "2            305  12.09  3.24\n",
      "3             97  13.23  2.50\n",
      "4             35  13.06  3.04\n",
      "{'test': 'ANOVA', 'stat': 15.876267993177123, 'p_value': 5.705728458962843e-10, 'significance': 'significant'}\n",
      "\n",
      "\n",
      "--- school_MS ---\n",
      "           count   mean   std\n",
      "school_MS                    \n",
      "False        423  12.58  2.63\n",
      "True         226  10.65  3.83\n",
      "{'test': 't-test', 'stat': 6.754491544530737, 'p_value': 6.211839408463177e-11, 'significance': 'significant'}\n",
      "\n",
      "\n",
      "--- sex_M ---\n",
      "       count   mean   std\n",
      "sex_M                    \n",
      "False    383  12.25  3.12\n",
      "True     266  11.41  3.32\n",
      "{'test': 't-test', 'stat': 3.274707393354231, 'p_value': 0.0011245651360440646, 'significance': 'significant'}\n",
      "\n",
      "\n",
      "--- address_U ---\n",
      "           count   mean   std\n",
      "address_U                    \n",
      "False        197  11.09  3.61\n",
      "True         452  12.26  2.99\n",
      "{'test': 't-test', 'stat': 4.019882754058349, 'p_value': 7.273853408915071e-05, 'significance': 'significant'}\n",
      "\n",
      "\n",
      "--- famsize_LE3 ---\n",
      "             count   mean   std\n",
      "famsize_LE3                    \n",
      "False          457  11.81  3.35\n",
      "True           192  12.13  2.92\n",
      "{'test': 't-test', 'stat': -1.2124111463814597, 'p_value': 0.2260555717236613, 'significance': 'not significant'}\n",
      "\n",
      "\n",
      "--- Pstatus_T ---\n",
      "           count   mean   std\n",
      "Pstatus_T                    \n",
      "False         80  11.91  3.22\n",
      "True         569  11.91  3.23\n",
      "{'test': 't-test', 'stat': 0.019231320017418424, 'p_value': 0.9846938929083802, 'significance': 'not significant'}\n",
      "\n",
      "\n",
      "--- Mjob_health ---\n",
      "             count   mean   std\n",
      "Mjob_health                    \n",
      "False          601  11.81  3.24\n",
      "True            48  13.06  2.96\n",
      "{'test': 't-test', 'stat': -2.7958713082734548, 'p_value': 0.007064435525998731, 'significance': 'significant'}\n",
      "\n",
      "\n",
      "--- Mjob_other ---\n",
      "            count   mean   std\n",
      "Mjob_other                    \n",
      "False         391  12.06  3.17\n",
      "True          258  11.67  3.31\n",
      "{'test': 't-test', 'stat': 1.497071773510237, 'p_value': 0.13496512328389107, 'significance': 'not significant'}\n",
      "\n",
      "\n",
      "--- Mjob_services ---\n",
      "               count   mean   std\n",
      "Mjob_services                    \n",
      "False            513  11.84  3.31\n",
      "True             136  12.15  2.92\n",
      "{'test': 't-test', 'stat': -1.0526811333456665, 'p_value': 0.29356595146021164, 'significance': 'not significant'}\n",
      "\n",
      "\n",
      "--- Mjob_teacher ---\n",
      "              count   mean   std\n",
      "Mjob_teacher                    \n",
      "False           577  11.75  3.19\n",
      "True             72  13.14  3.31\n",
      "{'test': 't-test', 'stat': -3.3676386996142873, 'p_value': 0.00112479242065707, 'significance': 'significant'}\n",
      "\n",
      "\n",
      "--- Fjob_health ---\n",
      "             count   mean   std\n",
      "Fjob_health                    \n",
      "False          626  11.88  3.23\n",
      "True            23  12.57  3.13\n",
      "{'test': 't-test', 'stat': -1.0269297293534743, 'p_value': 0.3147964230187771, 'significance': 'not significant'}\n",
      "\n",
      "\n",
      "--- Fjob_other ---\n",
      "            count   mean   std\n",
      "Fjob_other                    \n",
      "False         282  11.93  3.43\n",
      "True          367  11.89  3.07\n",
      "{'test': 't-test', 'stat': 0.13293683396012185, 'p_value': 0.8942903521374562, 'significance': 'not significant'}\n",
      "\n",
      "\n",
      "--- Fjob_services ---\n",
      "               count   mean   std\n",
      "Fjob_services                    \n",
      "False            468  12.01  3.14\n",
      "True             181  11.63  3.44\n",
      "{'test': 't-test', 'stat': 1.3026265555208438, 'p_value': 0.19369144826127904, 'significance': 'not significant'}\n",
      "\n",
      "\n",
      "--- Fjob_teacher ---\n",
      "              count   mean  std\n",
      "Fjob_teacher                   \n",
      "False           613  11.81  3.2\n",
      "True             36  13.58  3.4\n",
      "{'test': 't-test', 'stat': 3.055001320590682, 'p_value': 0.004061301923282283, 'significance': 'significant'}\n",
      "\n",
      "\n",
      "--- reason_home ---\n",
      "             count   mean   std\n",
      "reason_home                    \n",
      "False          500  11.82  3.31\n",
      "True           149  12.18  2.95\n",
      "{'test': 't-test', 'stat': -1.2599263676367725, 'p_value': 0.20879087919039097, 'significance': 'not significant'}\n",
      "\n",
      "\n",
      "--- reason_other ---\n",
      "              count   mean   std\n",
      "reason_other                    \n",
      "False           577  12.06  3.10\n",
      "True             72  10.69  3.93\n",
      "{'test': 't-test', 'stat': 2.833297059419703, 'p_value': 0.005790785715561964, 'significance': 'significant'}\n",
      "\n",
      "\n",
      "--- reason_reputation ---\n",
      "                   count   mean   std\n",
      "reason_reputation                    \n",
      "False                506  11.61  3.22\n",
      "True                 143  12.94  3.05\n",
      "{'test': 't-test', 'stat': -4.548137541340962, 'p_value': 8.611685826313288e-06, 'significance': 'significant'}\n",
      "\n",
      "\n",
      "--- guardian_mother ---\n",
      "                 count   mean   std\n",
      "guardian_mother                    \n",
      "False              194  11.93  3.12\n",
      "True               455  11.90  3.28\n",
      "{'test': 't-test', 'stat': -0.11457581758193049, 'p_value': 0.9088415952847346, 'significance': 'not significant'}\n",
      "\n",
      "\n",
      "--- guardian_other ---\n",
      "                count   mean   std\n",
      "guardian_other                    \n",
      "False             608  11.97  3.26\n",
      "True               41  10.90  2.62\n",
      "{'test': 't-test', 'stat': 2.4871393865930527, 'p_value': 0.016352451480525467, 'significance': 'significant'}\n",
      "\n",
      "\n",
      "--- schoolsup_yes ---\n",
      "               count   mean   std\n",
      "schoolsup_yes                    \n",
      "False            581  11.98  3.32\n",
      "True              68  11.28  2.30\n",
      "{'test': 't-test', 'stat': -2.247386399818792, 'p_value': 0.026753318027728606, 'significance': 'significant'}\n",
      "\n",
      "\n",
      "--- famsup_yes ---\n",
      "            count   mean   std\n",
      "famsup_yes                    \n",
      "False         251  11.67  3.60\n",
      "True          398  12.06  2.97\n",
      "{'test': 't-test', 'stat': -1.4444426859970576, 'p_value': 0.14929965323472838, 'significance': 'not significant'}\n",
      "\n",
      "\n",
      "--- paid_yes ---\n",
      "          count   mean   std\n",
      "paid_yes                    \n",
      "False       610  11.95  3.25\n",
      "True         39  11.21  2.85\n",
      "{'test': 't-test', 'stat': 1.5706937848074205, 'p_value': 0.1233266603059633, 'significance': 'not significant'}\n",
      "\n",
      "\n",
      "--- activities_yes ---\n",
      "                count   mean   std\n",
      "activities_yes                    \n",
      "False             334  11.72  3.24\n",
      "True              315  12.10  3.22\n",
      "{'test': 't-test', 'stat': -1.523819141233553, 'p_value': 0.12804391432557294, 'significance': 'not significant'}\n",
      "\n",
      "\n",
      "--- nursery_yes ---\n",
      "             count   mean   std\n",
      "nursery_yes                    \n",
      "False          128  11.72  3.01\n",
      "True           521  11.95  3.28\n",
      "{'test': 't-test', 'stat': 0.7719158733077556, 'p_value': 0.4410402283118574, 'significance': 'not significant'}\n",
      "\n",
      "\n",
      "--- higher_yes ---\n",
      "            count   mean   std\n",
      "higher_yes                    \n",
      "False          69   8.80  2.97\n",
      "True          580  12.28  3.06\n",
      "{'test': 't-test', 'stat': 9.159340304713666, 'p_value': 2.323053826942577e-14, 'significance': 'significant'}\n",
      "\n",
      "\n",
      "--- internet_yes ---\n",
      "              count   mean   std\n",
      "internet_yes                    \n",
      "False           151  11.03  3.45\n",
      "True            498  12.17  3.12\n",
      "{'test': 't-test', 'stat': -3.658007610910068, 'p_value': 0.0003153288773932979, 'significance': 'significant'}\n",
      "\n",
      "\n",
      "--- romantic_yes ---\n",
      "              count   mean   std\n",
      "romantic_yes                    \n",
      "False           410  12.13  3.00\n",
      "True            239  11.52  3.56\n",
      "{'test': 't-test', 'stat': 2.2129016125451826, 'p_value': 0.02742524893858476, 'significance': 'significant'}\n",
      "\n",
      "\n",
      "--- has_failures ---\n",
      "              count   mean   std\n",
      "has_failures                    \n",
      "0               549  12.51  2.83\n",
      "1               100   8.59  3.30\n",
      "{'test': 't-test', 'stat': 11.155338106225786, 'p_value': 1.4725346197605263e-20, 'significance': 'significant'}\n",
      "\n",
      "\n",
      "--- family_edu_max ---\n",
      "                count   mean   std\n",
      "family_edu_max                    \n",
      "0                   1  11.00   NaN\n",
      "1                  99  10.71  3.49\n",
      "2                 192  11.43  2.98\n",
      "3                 149  11.86  3.00\n",
      "4                 208  12.96  3.20\n",
      "{'test': 'ANOVA', 'stat': 14.082232166858963, 'p_value': 6.699714161091727e-09, 'significance': 'significant'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_vars = [\n",
    "    \"studytime\",\n",
    "    \"school_MS\",\n",
    "    \"sex_M\",\n",
    "    \"address_U\",\n",
    "    \"famsize_LE3\",\n",
    "    \"Pstatus_T\",\n",
    "    \"Mjob_health\",\n",
    "    \"Mjob_other\",\n",
    "    \"Mjob_services\",\n",
    "    \"Mjob_teacher\",\n",
    "    \"Fjob_health\",\n",
    "    \"Fjob_other\",\n",
    "    \"Fjob_services\",\n",
    "    \"Fjob_teacher\",\n",
    "    \"reason_home\",\n",
    "    \"reason_other\",\n",
    "    \"reason_reputation\",\n",
    "    \"guardian_mother\",\n",
    "    \"guardian_other\",\n",
    "    \"schoolsup_yes\",\n",
    "    \"famsup_yes\",\n",
    "    \"paid_yes\",\n",
    "    \"activities_yes\",\n",
    "    \"nursery_yes\",\n",
    "    \"higher_yes\",\n",
    "    \"internet_yes\",\n",
    "    \"romantic_yes\",\n",
    "    \"has_failures\",\n",
    "    \"family_edu_max\",\n",
    "]\n",
    "\n",
    "for col in categorical_vars:\n",
    "    groups, result = compare_groups(df, col, \"G3\")\n",
    "    print(f\"--- {col} ---\")\n",
    "    print(groups)\n",
    "    print(result)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d379d1c1",
   "metadata": {},
   "source": [
    "3.4 HYPOTHESIS TESTING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b0cea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HYPOTHESIS 1: Higher study time ‚Üí Better performance\n",
      "Study time - G3 correlation: 0.250\n",
      "Average G3 by study time:\n",
      "  Study time 1: 10.84\n",
      "  Study time 2: 12.09\n",
      "  Study time 3: 13.23\n",
      "  Study time 4: 13.06\n",
      "Result: SUPPORTED (p-value: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Hypothesis 1: Students with higher study time perform better\n",
    "print(\"\\nHYPOTHESIS 1: Higher study time ‚Üí Better performance\")\n",
    "if \"studytime\" in df.columns and \"G3\" in df.columns:\n",
    "    corr_study_g3 = df[\"studytime\"].corr(df[\"G3\"])\n",
    "    print(f\"Study time - G3 correlation: {corr_study_g3:.3f}\")\n",
    "\n",
    "    # Group analysis\n",
    "    study_groups = df.groupby(\"studytime\")[\"G3\"].mean()\n",
    "    print(f\"Average G3 by study time:\")\n",
    "    for time, avg_grade in study_groups.items():\n",
    "        print(f\"  Study time {time}: {avg_grade:.2f}\")\n",
    "\n",
    "    # Test high vs low study time\n",
    "    high_study = df[df[\"studytime\"] >= 3][\"G3\"]\n",
    "    low_study = df[df[\"studytime\"] <= 2][\"G3\"]\n",
    "    stat, p_val = ttest_ind(high_study, low_study)\n",
    "    result = (\n",
    "        \"SUPPORTED\"\n",
    "        if p_val < 0.05 and high_study.mean() > low_study.mean()\n",
    "        else \"NOT SUPPORTED\"\n",
    "    )\n",
    "    print(f\"Result: {result} (p-value: {p_val:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9403d50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HYPOTHESIS 2: School support ‚Üí Better performance\n",
      "With school support: 11.28\n",
      "Without school support: 11.98\n",
      "Result: NOT SUPPORTED (p-value: 0.0910)\n"
     ]
    }
   ],
   "source": [
    "# Hypothesis 2: Students with school support perform better\n",
    "print(\"\\nHYPOTHESIS 2: School support ‚Üí Better performance\")\n",
    "if \"schoolsup_yes\" in df.columns and \"G3\" in df.columns:\n",
    "    support_yes = df[df[\"schoolsup_yes\"] == 1][\"G3\"]\n",
    "    support_no = df[df[\"schoolsup_yes\"] == 0][\"G3\"]\n",
    "    stat, p_val = ttest_ind(support_yes, support_no)\n",
    "    print(f\"With school support: {support_yes.mean():.2f}\")\n",
    "    print(f\"Without school support: {support_no.mean():.2f}\")\n",
    "    result = (\n",
    "        \"SUPPORTED\"\n",
    "        if p_val < 0.05 and support_yes.mean() > support_no.mean()\n",
    "        else \"NOT SUPPORTED\"\n",
    "    )\n",
    "    print(f\"Result: {result} (p-value: {p_val:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc4c3a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HYPOTHESIS 3: Higher absences ‚Üí Lower performance\n",
      "Absences - G3 correlation: -0.099\n",
      "High absences avg G3: 11.66\n",
      "Low absences avg G3: 12.10\n",
      "Result: NOT SUPPORTED (p-value: 0.0845)\n"
     ]
    }
   ],
   "source": [
    "# Hypothesis 3: Higher absences lead to lower performance\n",
    "print(\"\\nHYPOTHESIS 3: Higher absences ‚Üí Lower performance\")\n",
    "if \"absences\" in df.columns and \"G3\" in df.columns:\n",
    "    corr_abs_g3 = df[\"absences\"].corr(df[\"G3\"])\n",
    "    print(f\"Absences - G3 correlation: {corr_abs_g3:.3f}\")\n",
    "\n",
    "    high_absence = df[df[\"absences\"] > df[\"absences\"].median()][\"G3\"]\n",
    "    low_absence = df[df[\"absences\"] <= df[\"absences\"].median()][\"G3\"]\n",
    "    stat, p_val = ttest_ind(high_absence, low_absence)\n",
    "    result = \"SUPPORTED\" if p_val < 0.05 and corr_abs_g3 < 0 else \"NOT SUPPORTED\"\n",
    "    print(f\"High absences avg G3: {high_absence.mean():.2f}\")\n",
    "    print(f\"Low absences avg G3: {low_absence.mean():.2f}\")\n",
    "    print(f\"Result: {result} (p-value: {p_val:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abe3d380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HYPOTHESIS 3: Higher absences ‚Üí Lower performance\n",
      "Absences - G3 correlation: -0.099\n",
      "High absences avg G3: 11.66\n",
      "Low absences avg G3: 12.10\n",
      "Result: NOT SUPPORTED (p-value: 0.0845)\n"
     ]
    }
   ],
   "source": [
    "# Hypothesis 3: Higher absences lead to lower performance\n",
    "print(\"\\nHYPOTHESIS 3: Higher absences ‚Üí Lower performance\")\n",
    "if \"absences\" in df.columns and \"G3\" in df.columns:\n",
    "    corr_abs_g3 = df[\"absences\"].corr(df[\"G3\"])\n",
    "    print(f\"Absences - G3 correlation: {corr_abs_g3:.3f}\")\n",
    "\n",
    "    high_absence = df[df[\"absences\"] > df[\"absences\"].median()][\"G3\"]\n",
    "    low_absence = df[df[\"absences\"] <= df[\"absences\"].median()][\"G3\"]\n",
    "    stat, p_val = ttest_ind(high_absence, low_absence)\n",
    "    result = \"SUPPORTED\" if p_val < 0.05 and corr_abs_g3 < 0 else \"NOT SUPPORTED\"\n",
    "    print(f\"High absences avg G3: {high_absence.mean():.2f}\")\n",
    "    print(f\"Low absences avg G3: {low_absence.mean():.2f}\")\n",
    "    print(f\"Result: {result} (p-value: {p_val:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b6f7437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HYPOTHESIS 4: Past failures ‚Üí Lower performance\n",
      "No past failures avg G3: 12.51\n",
      "With past failures avg G3: 8.59\n",
      "Result: SUPPORTED (p-value: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Hypothesis 4: Past failures predict current performance\n",
    "print(\"\\nHYPOTHESIS 4: Past failures ‚Üí Lower performance\")\n",
    "if \"failures\" in df.columns and \"G3\" in df.columns:\n",
    "    no_failures = df[df[\"failures\"] == 0][\"G3\"]\n",
    "    with_failures = df[df[\"failures\"] > 0][\"G3\"]\n",
    "    stat, p_val = ttest_ind(no_failures, with_failures)\n",
    "    print(f\"No past failures avg G3: {no_failures.mean():.2f}\")\n",
    "    print(f\"With past failures avg G3: {with_failures.mean():.2f}\")\n",
    "    result = (\n",
    "        \"SUPPORTED\"\n",
    "        if p_val < 0.05 and no_failures.mean() > with_failures.mean()\n",
    "        else \"NOT SUPPORTED\"\n",
    "    )\n",
    "    print(f\"Result: {result} (p-value: {p_val:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "267898a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HYPOTHESIS 5: Higher family education ‚Üí Better performance\n",
      "Family education - G3 correlation: 0.249\n",
      "High family education avg G3: 12.80\n",
      "Low family education avg G3: 11.34\n",
      "Result: SUPPORTED (p-value: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Hypothesis 5: Family education level affects performance\n",
    "print(\"\\nHYPOTHESIS 5: Higher family education ‚Üí Better performance\")\n",
    "if \"family_edu_avg\" in df.columns and \"G3\" in df.columns:\n",
    "    corr_fam_edu_g3 = df[\"family_edu_avg\"].corr(df[\"G3\"])\n",
    "    print(f\"Family education - G3 correlation: {corr_fam_edu_g3:.3f}\")\n",
    "\n",
    "    high_edu = df[df[\"family_edu_avg\"] >= 3][\"G3\"]\n",
    "    low_edu = df[df[\"family_edu_avg\"] < 3][\"G3\"]\n",
    "    stat, p_val = ttest_ind(high_edu, low_edu)\n",
    "    result = \"SUPPORTED\" if p_val < 0.05 and corr_fam_edu_g3 > 0 else \"NOT SUPPORTED\"\n",
    "    print(f\"High family education avg G3: {high_edu.mean():.2f}\")\n",
    "    print(f\"Low family education avg G3: {low_edu.mean():.2f}\")\n",
    "    print(f\"Result: {result} (p-value: {p_val:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d70a503",
   "metadata": {},
   "source": [
    "3.5 BEHAVIORAL PATTERNS ANALYSIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14458628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student behavioral patterns and their relationship with performance:\n",
      "=================================================================\n",
      "HIGH PERFORMERS (n=549):\n",
      "  ‚Ä¢ studytime: 1.99\n",
      "  ‚Ä¢ goout: 3.15\n",
      "  ‚Ä¢ freetime: 3.14\n",
      "  ‚Ä¢ absences: 3.36\n",
      "\n",
      "LOW PERFORMERS (n=100):\n",
      "  ‚Ä¢ studytime: 1.61\n",
      "  ‚Ä¢ goout: 3.37\n",
      "  ‚Ä¢ freetime: 3.41\n",
      "  ‚Ä¢ absences: 4.32\n",
      "\n",
      "KEY BEHAVIORAL DIFFERENCES:\n",
      "  ‚Ä¢ High performers have higher studytime (+0.38)\n",
      "  ‚Ä¢ High performers have lower goout (-0.22)\n",
      "  ‚Ä¢ High performers have lower freetime (-0.27)\n",
      "  ‚Ä¢ High performers have lower absences (-0.96)\n"
     ]
    }
   ],
   "source": [
    "# Create behavioral profile\n",
    "behavioral_vars = [\"studytime\", \"goout\", \"freetime\", \"absences\"]\n",
    "available_behavioral = [var for var in behavioral_vars if var in df.columns]\n",
    "\n",
    "if available_behavioral:\n",
    "    print(\"Student behavioral patterns and their relationship with performance:\")\n",
    "    print(\"=\" * 65)\n",
    "\n",
    "    # High performers vs Low performers\n",
    "    if \"pass_binary\" in df.columns:\n",
    "        high_performers = df[df[\"pass_binary\"] == 1]\n",
    "        low_performers = df[df[\"pass_binary\"] == 0]\n",
    "\n",
    "        print(f\"HIGH PERFORMERS (n={len(high_performers)}):\")\n",
    "        for var in available_behavioral:\n",
    "            mean_high = high_performers[var].mean()\n",
    "            print(f\"  ‚Ä¢ {var}: {mean_high:.2f}\")\n",
    "\n",
    "        print(f\"\\nLOW PERFORMERS (n={len(low_performers)}):\")\n",
    "        for var in available_behavioral:\n",
    "            mean_low = low_performers[var].mean()\n",
    "            print(f\"  ‚Ä¢ {var}: {mean_low:.2f}\")\n",
    "\n",
    "        print(f\"\\nKEY BEHAVIORAL DIFFERENCES:\")\n",
    "        for var in available_behavioral:\n",
    "            diff = high_performers[var].mean() - low_performers[var].mean()\n",
    "            direction = \"higher\" if diff > 0 else \"lower\"\n",
    "            print(f\"  ‚Ä¢ High performers have {direction} {var} ({diff:+.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993e36af",
   "metadata": {},
   "source": [
    "3.6 FEATURE IMPORTANCE FOR CLUSTERING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a56004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8. FEATURE ANALYSIS FOR CLUSTERING\n",
      "--------------------------------------\n",
      "Behavioral clustering features summary:\n",
      "       studytime  absences   goout  freetime  attendance_rate\n",
      "count     649.00    649.00  649.00    649.00           649.00\n",
      "mean        1.93      3.51    3.18      3.18             0.77\n",
      "std         0.83      4.09    1.18      1.05             0.27\n",
      "min         1.00      0.00    1.00      1.00             0.00\n",
      "25%         1.00      0.00    2.00      3.00             0.60\n",
      "50%         2.00      2.00    3.00      3.00             0.87\n",
      "75%         2.00      6.00    4.00      4.00             1.00\n",
      "max         4.00     15.00    5.00      5.00             1.00\n",
      "\n",
      "Feature variance (higher = more discriminative):\n",
      "  ‚Ä¢ studytime: 0.688\n",
      "  ‚Ä¢ absences: 16.695\n",
      "  ‚Ä¢ goout: 1.382\n",
      "  ‚Ä¢ freetime: 1.105\n",
      "  ‚Ä¢ attendance_rate: 0.074\n"
     ]
    }
   ],
   "source": [
    "# Analyze clustering features\n",
    "clustering_features = [\"studytime\", \"absences\", \"goout\", \"freetime\", \"attendance_rate\"]\n",
    "available_clustering = [feat for feat in clustering_features if feat in df.columns]\n",
    "\n",
    "if available_clustering:\n",
    "    print(\"Behavioral clustering features summary:\")\n",
    "    cluster_stats = df[available_clustering].describe().round(2)\n",
    "    print(cluster_stats.to_string())\n",
    "\n",
    "    # Calculate feature variance (important for clustering)\n",
    "    print(f\"\\nFeature variance (higher = more discriminative):\")\n",
    "    for feat in available_clustering:\n",
    "        variance = df[feat].var()\n",
    "        print(f\"  ‚Ä¢ {feat}: {variance:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9117e0",
   "metadata": {},
   "source": [
    "3.6 ADDITIONAL EDA INSIGHTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee9ddef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outlier Analysis\n",
      "==================================================\n",
      "\n",
      "Outlier Summary:\n",
      "\n",
      "age:\n",
      "- Number of outliers: 1\n",
      "- Outlier boundaries: [13.00, 21.00]\n",
      "- Actual range: [15.00, 22.00]\n",
      "\n",
      "traveltime:\n",
      "- Number of outliers: 16\n",
      "- Outlier boundaries: [-0.50, 3.50]\n",
      "- Actual range: [1.00, 4.00]\n",
      "\n",
      "failures:\n",
      "- Number of outliers: 100\n",
      "- Outlier boundaries: [0.00, 0.00]\n",
      "- Actual range: [0.00, 3.00]\n",
      "\n",
      "famrel:\n",
      "- Number of outliers: 51\n",
      "- Outlier boundaries: [2.50, 6.50]\n",
      "- Actual range: [1.00, 5.00]\n",
      "\n",
      "freetime:\n",
      "- Number of outliers: 45\n",
      "- Outlier boundaries: [1.50, 5.50]\n",
      "- Actual range: [1.00, 5.00]\n",
      "\n",
      "Dalc:\n",
      "- Number of outliers: 34\n",
      "- Outlier boundaries: [-0.50, 3.50]\n",
      "- Actual range: [1.00, 5.00]\n",
      "\n",
      "G3:\n",
      "- Number of outliers: 16\n",
      "- Outlier boundaries: [4.00, 20.00]\n",
      "- Actual range: [0.00, 19.00]\n",
      "\n",
      "pass_binary:\n",
      "- Number of outliers: 100\n",
      "- Outlier boundaries: [1.00, 1.00]\n",
      "- Actual range: [0.00, 1.00]\n",
      "\n",
      "study_efficiency:\n",
      "- Number of outliers: 13\n",
      "- Outlier boundaries: [0.83, 7.50]\n",
      "- Actual range: [0.56, 8.83]\n"
     ]
    }
   ],
   "source": [
    "# 2. Outlier Analysis\n",
    "print(\"\\nOutlier Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "\n",
    "def detect_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)][column]\n",
    "    return len(outliers), lower_bound, upper_bound\n",
    "\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "print(\"\\nOutlier Summary:\")\n",
    "for column in numerical_columns:\n",
    "    n_outliers, lower, upper = detect_outliers(df, column)\n",
    "    if n_outliers > 0:\n",
    "        print(f\"\\n{column}:\")\n",
    "        print(f\"- Number of outliers: {n_outliers}\")\n",
    "        print(f\"- Outlier boundaries: [{lower:.2f}, {upper:.2f}]\")\n",
    "        print(f\"- Actual range: [{df[column].min():.2f}, {df[column].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192ed4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categorical Variable Analysis\n",
      "==================================================\n",
      "\n",
      "Category Distribution:\n",
      "\n",
      "studytime:\n",
      "- 2: 305 (47.0%)\n",
      "- 1: 212 (32.7%)\n",
      "- 3: 97 (14.9%)\n",
      "- 4: 35 (5.4%)\n",
      "\n",
      "school_MS:\n",
      "- False: 423 (65.2%)\n",
      "- True: 226 (34.8%)\n",
      "\n",
      "sex_M:\n",
      "- False: 383 (59.0%)\n",
      "- True: 266 (41.0%)\n",
      "\n",
      "address_U:\n",
      "- True: 452 (69.6%)\n",
      "- False: 197 (30.4%)\n",
      "\n",
      "famsize_LE3:\n",
      "- False: 457 (70.4%)\n",
      "- True: 192 (29.6%)\n",
      "\n",
      "Pstatus_T:\n",
      "- True: 569 (87.7%)\n",
      "- False: 80 (12.3%)\n",
      "\n",
      "Mjob_health:\n",
      "- False: 601 (92.6%)\n",
      "- True: 48 (7.4%)\n",
      "\n",
      "Mjob_other:\n",
      "- False: 391 (60.2%)\n",
      "- True: 258 (39.8%)\n",
      "\n",
      "Mjob_services:\n",
      "- False: 513 (79.0%)\n",
      "- True: 136 (21.0%)\n",
      "\n",
      "Mjob_teacher:\n",
      "- False: 577 (88.9%)\n",
      "- True: 72 (11.1%)\n",
      "\n",
      "Fjob_health:\n",
      "- False: 626 (96.5%)\n",
      "- True: 23 (3.5%)\n",
      "\n",
      "Fjob_other:\n",
      "- True: 367 (56.5%)\n",
      "- False: 282 (43.5%)\n",
      "\n",
      "Fjob_services:\n",
      "- False: 468 (72.1%)\n",
      "- True: 181 (27.9%)\n",
      "\n",
      "Fjob_teacher:\n",
      "- False: 613 (94.5%)\n",
      "- True: 36 (5.5%)\n",
      "\n",
      "reason_home:\n",
      "- False: 500 (77.0%)\n",
      "- True: 149 (23.0%)\n",
      "\n",
      "reason_other:\n",
      "- False: 577 (88.9%)\n",
      "- True: 72 (11.1%)\n",
      "\n",
      "reason_reputation:\n",
      "- False: 506 (78.0%)\n",
      "- True: 143 (22.0%)\n",
      "\n",
      "guardian_mother:\n",
      "- True: 455 (70.1%)\n",
      "- False: 194 (29.9%)\n",
      "\n",
      "guardian_other:\n",
      "- False: 608 (93.7%)\n",
      "- True: 41 (6.3%)\n",
      "\n",
      "schoolsup_yes:\n",
      "- False: 581 (89.5%)\n",
      "- True: 68 (10.5%)\n",
      "\n",
      "famsup_yes:\n",
      "- True: 398 (61.3%)\n",
      "- False: 251 (38.7%)\n",
      "\n",
      "paid_yes:\n",
      "- False: 610 (94.0%)\n",
      "- True: 39 (6.0%)\n",
      "\n",
      "activities_yes:\n",
      "- False: 334 (51.5%)\n",
      "- True: 315 (48.5%)\n",
      "\n",
      "nursery_yes:\n",
      "- True: 521 (80.3%)\n",
      "- False: 128 (19.7%)\n",
      "\n",
      "higher_yes:\n",
      "- True: 580 (89.4%)\n",
      "- False: 69 (10.6%)\n",
      "\n",
      "internet_yes:\n",
      "- True: 498 (76.7%)\n",
      "- False: 151 (23.3%)\n",
      "\n",
      "romantic_yes:\n",
      "- False: 410 (63.2%)\n",
      "- True: 239 (36.8%)\n",
      "\n",
      "risk_category:\n",
      "- Medium_Risk: 355 (54.7%)\n",
      "- Low_Risk: 194 (29.9%)\n",
      "- High_Risk: 100 (15.4%)\n",
      "\n",
      "has_failures:\n",
      "- 0: 549 (84.6%)\n",
      "- 1: 100 (15.4%)\n",
      "\n",
      "family_edu_max:\n",
      "- 4: 208 (32.0%)\n",
      "- 2: 192 (29.6%)\n",
      "- 3: 149 (23.0%)\n",
      "- 1: 99 (15.3%)\n",
      "- 0: 1 (0.2%)\n"
     ]
    }
   ],
   "source": [
    "# 3. Categorical Variable Analysis\n",
    "print(\"\\nCategorical Variable Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "categorical_columns = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "if len(categorical_columns) > 0:\n",
    "    print(\"\\nCategory Distribution:\")\n",
    "    for column in categorical_columns:\n",
    "        value_counts = df[column].value_counts()\n",
    "        percentages = df[column].value_counts(normalize=True) * 100\n",
    "\n",
    "        print(f\"\\n{column}:\")\n",
    "        for value, count in value_counts.items():\n",
    "            percentage = percentages[value]\n",
    "            print(f\"- {value}: {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183fea9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Distribution Analysis\n",
      "==================================================\n",
      "\n",
      "age Distribution:\n",
      "- Mean: 16.74\n",
      "- Median: 17.00\n",
      "- Mode: 17.00\n",
      "- Standard Deviation: 1.22\n",
      "- Coefficient of Variation: 0.07\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: 0.42 (symmetric with right skew)\n",
      "  ‚Ä¢ Kurtosis: 0.07 (normal heavy-tailed)\n",
      "\n",
      "Medu Distribution:\n",
      "- Mean: 2.51\n",
      "- Median: 2.00\n",
      "- Mode: 2.00\n",
      "- Standard Deviation: 1.13\n",
      "- Coefficient of Variation: 0.45\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: -0.03 (symmetric with left skew)\n",
      "  ‚Ä¢ Kurtosis: -1.26 (extreme light-tailed)\n",
      "\n",
      "Fedu Distribution:\n",
      "- Mean: 2.31\n",
      "- Median: 2.00\n",
      "- Mode: 2.00\n",
      "- Standard Deviation: 1.10\n",
      "- Coefficient of Variation: 0.48\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: 0.22 (symmetric with right skew)\n",
      "  ‚Ä¢ Kurtosis: -1.11 (extreme light-tailed)\n",
      "\n",
      "traveltime Distribution:\n",
      "- Mean: 1.57\n",
      "- Median: 1.00\n",
      "- Mode: 1.00\n",
      "- Standard Deviation: 0.75\n",
      "- Coefficient of Variation: 0.48\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: 1.25 (highly skewed with right skew)\n",
      "  ‚Ä¢ Kurtosis: 1.11 (extreme heavy-tailed)\n",
      "\n",
      "failures Distribution:\n",
      "- Mean: 0.22\n",
      "- Median: 0.00\n",
      "- Mode: 0.00\n",
      "- Standard Deviation: 0.59\n",
      "- Coefficient of Variation: 2.67\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: 3.09 (highly skewed with right skew)\n",
      "  ‚Ä¢ Kurtosis: 9.82 (extreme heavy-tailed)\n",
      "\n",
      "famrel Distribution:\n",
      "- Mean: 3.93\n",
      "- Median: 4.00\n",
      "- Mode: 4.00\n",
      "- Standard Deviation: 0.96\n",
      "- Coefficient of Variation: 0.24\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: -1.11 (highly skewed with left skew)\n",
      "  ‚Ä¢ Kurtosis: 1.35 (extreme heavy-tailed)\n",
      "\n",
      "freetime Distribution:\n",
      "- Mean: 3.18\n",
      "- Median: 3.00\n",
      "- Mode: 3.00\n",
      "- Standard Deviation: 1.05\n",
      "- Coefficient of Variation: 0.33\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: -0.18 (symmetric with left skew)\n",
      "  ‚Ä¢ Kurtosis: -0.40 (normal light-tailed)\n",
      "\n",
      "goout Distribution:\n",
      "- Mean: 3.18\n",
      "- Median: 3.00\n",
      "- Mode: 3.00\n",
      "- Standard Deviation: 1.18\n",
      "- Coefficient of Variation: 0.37\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: -0.01 (symmetric with left skew)\n",
      "  ‚Ä¢ Kurtosis: -0.87 (moderate light-tailed)\n",
      "\n",
      "Dalc Distribution:\n",
      "- Mean: 1.50\n",
      "- Median: 1.00\n",
      "- Mode: 1.00\n",
      "- Standard Deviation: 0.92\n",
      "- Coefficient of Variation: 0.62\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: 2.14 (highly skewed with right skew)\n",
      "  ‚Ä¢ Kurtosis: 4.35 (extreme heavy-tailed)\n",
      "\n",
      "Walc Distribution:\n",
      "- Mean: 2.28\n",
      "- Median: 2.00\n",
      "- Mode: 1.00\n",
      "- Standard Deviation: 1.28\n",
      "- Coefficient of Variation: 0.56\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: 0.64 (moderately skewed with right skew)\n",
      "  ‚Ä¢ Kurtosis: -0.77 (moderate light-tailed)\n",
      "\n",
      "health Distribution:\n",
      "- Mean: 3.54\n",
      "- Median: 4.00\n",
      "- Mode: 5.00\n",
      "- Standard Deviation: 1.45\n",
      "- Coefficient of Variation: 0.41\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: -0.50 (moderately skewed with left skew)\n",
      "  ‚Ä¢ Kurtosis: -1.12 (extreme light-tailed)\n",
      "\n",
      "absences Distribution:\n",
      "- Mean: 3.51\n",
      "- Median: 2.00\n",
      "- Mode: 0.00\n",
      "- Standard Deviation: 4.09\n",
      "- Coefficient of Variation: 1.16\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: 1.25 (highly skewed with right skew)\n",
      "  ‚Ä¢ Kurtosis: 0.81 (moderate heavy-tailed)\n",
      "\n",
      "G3 Distribution:\n",
      "- Mean: 11.91\n",
      "- Median: 12.00\n",
      "- Mode: 11.00\n",
      "- Standard Deviation: 3.23\n",
      "- Coefficient of Variation: 0.27\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: -0.91 (moderately skewed with left skew)\n",
      "  ‚Ä¢ Kurtosis: 2.71 (extreme heavy-tailed)\n",
      "\n",
      "attendance_rate Distribution:\n",
      "- Mean: 0.77\n",
      "- Median: 0.87\n",
      "- Mode: 1.00\n",
      "- Standard Deviation: 0.27\n",
      "- Coefficient of Variation: 0.36\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: -1.25 (highly skewed with left skew)\n",
      "  ‚Ä¢ Kurtosis: 0.81 (moderate heavy-tailed)\n",
      "\n",
      "pass_binary Distribution:\n",
      "- Mean: 0.85\n",
      "- Median: 1.00\n",
      "- Mode: 1.00\n",
      "- Standard Deviation: 0.36\n",
      "- Coefficient of Variation: 0.43\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: -1.92 (highly skewed with left skew)\n",
      "  ‚Ä¢ Kurtosis: 1.69 (extreme heavy-tailed)\n",
      "\n",
      "study_efficiency Distribution:\n",
      "- Mean: 4.20\n",
      "- Median: 4.11\n",
      "- Mode: 3.33\n",
      "- Standard Deviation: 1.35\n",
      "- Coefficient of Variation: 0.32\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: 0.47 (symmetric with right skew)\n",
      "  ‚Ä¢ Kurtosis: 0.49 (normal heavy-tailed)\n",
      "\n",
      "family_edu_avg Distribution:\n",
      "- Mean: 2.41\n",
      "- Median: 2.50\n",
      "- Mode: 2.00\n",
      "- Standard Deviation: 1.01\n",
      "- Coefficient of Variation: 0.42\n",
      "- Distribution Shape:\n",
      "  ‚Ä¢ Skewness: 0.12 (symmetric with right skew)\n",
      "  ‚Ä¢ Kurtosis: -1.13 (extreme light-tailed)\n"
     ]
    }
   ],
   "source": [
    "# 4. Feature Distribution Analysis\n",
    "print(\"\\nFeature Distribution Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "\n",
    "for column in numerical_columns:\n",
    "    distribution_stats = df[column].describe()\n",
    "\n",
    "    print(f\"\\n{column} Distribution:\")\n",
    "    print(f\"- Mean: {distribution_stats['mean']:.2f}\")\n",
    "    print(f\"- Median: {distribution_stats['50%']:.2f}\")\n",
    "    print(f\"- Mode: {df[column].mode().values[0]:.2f}\")\n",
    "    print(f\"- Standard Deviation: {distribution_stats['std']:.2f}\")\n",
    "    print(\n",
    "        f\"- Coefficient of Variation: {(distribution_stats['std'] / distribution_stats['mean']):.2f}\"\n",
    "    )\n",
    "\n",
    "    # Distribution shape\n",
    "    skewness = df[column].skew()\n",
    "    kurtosis = df[column].kurtosis()\n",
    "\n",
    "    # Interpret distribution shape\n",
    "    skew_interpretation = (\n",
    "        \"symmetric\"\n",
    "        if abs(skewness) < 0.5\n",
    "        else \"moderately skewed\" if abs(skewness) < 1 else \"highly skewed\"\n",
    "    )\n",
    "    skew_direction = \"right\" if skewness > 0 else \"left\" if skewness < 0 else \"none\"\n",
    "\n",
    "    kurt_interpretation = (\n",
    "        \"normal\"\n",
    "        if abs(kurtosis) < 0.5\n",
    "        else \"moderate\" if abs(kurtosis) < 1 else \"extreme\"\n",
    "    )\n",
    "    kurt_direction = (\n",
    "        \"heavy-tailed\"\n",
    "        if kurtosis > 0\n",
    "        else \"light-tailed\" if kurtosis < 0 else \"normal-tailed\"\n",
    "    )\n",
    "\n",
    "    print(f\"- Distribution Shape:\")\n",
    "    print(\n",
    "        f\"  ‚Ä¢ Skewness: {skewness:.2f} ({skew_interpretation} with {skew_direction} skew)\"\n",
    "    )\n",
    "    print(f\"  ‚Ä¢ Kurtosis: {kurtosis:.2f} ({kurt_interpretation} {kurt_direction})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4800e85c",
   "metadata": {},
   "source": [
    "3.7 EDA INSIGHTS SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8ef9d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEY INSIGHTS:\n",
      "1. Age range: 15-22 years (avg: 16.7)\n",
      "2. Study efficiency impact: r=0.528 (strongest academic predictor)\n",
      "3. Students with high study time (3-4 hrs): 20.3%\n",
      "4. Risk distribution: 15.4% high, 54.7% medium\n",
      "5. Family education influence: r=0.249\n",
      "6. Attendance correlation: r=0.099\n",
      "7. Impact of past failures: nan grade points\n",
      "8. Average final grade: 11.9/20\n",
      "9. Overall pass rate: 84.6%\n",
      "10. Strongest predictor: pass_binary (r=0.663)\n",
      "11. Study time correlation with grades: 0.250\n",
      "12. Absence impact on grades: -0.099\n",
      "\n",
      "============================================================\n",
      "EXPLORATORY DATA ANALYSIS COMPLETE \n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "insights = []\n",
    "# Demographic insights\n",
    "insights.append(\n",
    "    f\"Age range: {df['age'].min()}-{df['age'].max()} years (avg: {df['age'].mean():.1f})\"\n",
    ")\n",
    "\n",
    "# Study behavior insights\n",
    "study_corr = df[\"studytime\"].corr(df[\"G3\"])\n",
    "study_eff_corr = df[\"study_efficiency\"].corr(df[\"G3\"])\n",
    "insights.append(\n",
    "    f\"Study efficiency impact: r={study_eff_corr:.3f} (strongest academic predictor)\"\n",
    ")\n",
    "insights.append(\n",
    "    f\"Students with high study time (3-4 hrs): {len(df[df['studytime'].astype(int) >= 3])/len(df):.1%}\"\n",
    ")\n",
    "\n",
    "# Risk patterns\n",
    "risk_dist = df[\"risk_category\"].value_counts(normalize=True)\n",
    "insights.append(\n",
    "    f\"Risk distribution: {risk_dist['High_Risk']:.1%} high, {risk_dist['Medium_Risk']:.1%} medium\"\n",
    ")\n",
    "\n",
    "# Family background impact\n",
    "fam_edu_corr = df[\"family_edu_avg\"].corr(df[\"G3\"])\n",
    "insights.append(f\"Family education influence: r={fam_edu_corr:.3f}\")\n",
    "\n",
    "# Attendance patterns\n",
    "att_corr = df[\"attendance_rate\"].corr(df[\"G3\"])\n",
    "insights.append(f\"Attendance correlation: r={att_corr:.3f}\")\n",
    "\n",
    "# Failure rate impact\n",
    "if \"has_failures\" in df.columns:\n",
    "    fail_impact = (\n",
    "        df[df[\"has_failures\"] == 1][\"G3\"].mean()\n",
    "        - df[df[\"has_failures\"] == 0][\"G3\"].mean()\n",
    "    )\n",
    "    insights.append(f\"Impact of past failures: {fail_impact:.1f} grade points\")\n",
    "# Generate insights based on analysis\n",
    "if \"G3\" in df.columns:\n",
    "    avg_grade = df[\"G3\"].mean()\n",
    "    pass_rate = df[\"pass_binary\"].mean() if \"pass_binary\" in df.columns else None\n",
    "    insights.append(f\"Average final grade: {avg_grade:.1f}/20\")\n",
    "    if pass_rate:\n",
    "        insights.append(f\"Overall pass rate: {pass_rate:.1%}\")\n",
    "\n",
    "# Top correlations\n",
    "if \"G3\" in df.columns:\n",
    "    num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "    if len(num_cols) > 1:\n",
    "        corrs = df[num_cols].corr()[\"G3\"].abs().sort_values(ascending=False)\n",
    "        top_predictor = corrs.index[1]  # Skip G3 itself\n",
    "        top_corr = corrs.iloc[1]\n",
    "        insights.append(f\"Strongest predictor: {top_predictor} (r={top_corr:.3f})\")\n",
    "\n",
    "# Behavioral insights\n",
    "if \"studytime\" in df.columns and \"G3\" in df.columns:\n",
    "    study_corr = df[\"studytime\"].corr(df[\"G3\"])\n",
    "    insights.append(f\"Study time correlation with grades: {study_corr:.3f}\")\n",
    "\n",
    "if \"absences\" in df.columns and \"G3\" in df.columns:\n",
    "    abs_corr = df[\"absences\"].corr(df[\"G3\"])\n",
    "    insights.append(f\"Absence impact on grades: {abs_corr:.3f}\")\n",
    "\n",
    "print(\"KEY INSIGHTS:\")\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"{i}. {insight}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPLORATORY DATA ANALYSIS COMPLETE \")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
